{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "/usr/lib/python3/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test data and drop index column\n",
    "df_train = pd.read_csv('/home/siamak/Projects/deep_learning/src/test_program/train_data/data.csv', index_col=0)\n",
    "df_test = pd.read_csv('/home/siamak/Projects/deep_learning/src/test_program/test_data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616656, 19)\n",
      "(154165, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns in train and test data\n",
    "df_train.drop(['Start_time', 'End_time', 'Name of show', 'Name of episode'], axis=1, inplace=True)\n",
    "df_test.drop(['Start_time', 'End_time', 'Name of show', 'Name of episode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train label\n",
    "train_label = df_train['Market Share_total']\n",
    "df_train.drop(['Market Share_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Episode  Station     Channel Type Season  Year        Date  \\\n",
      "1  Vid√©oclips V  V Total  General Channel   Fall  2016  2016-08-29   \n",
      "\n",
      "  Day of week  Length              Genre First time or rerun  \\\n",
      "1      Monday       8  Music Video Clips                  No   \n",
      "\n",
      "  # of episode in the season Movie? Game of the Canadiens during episode?  \\\n",
      "1                        Yes     No                                    No   \n",
      "\n",
      "   Temperature in Montreal during episode  \n",
      "1                                    20.4  \n",
      "-------------------------------------------------\n",
      "        Episode Station       Channel Type  Season  Year        Date  \\\n",
      "1  Mom V.F. (M)   VRAK+  Specialty Channel  Winter  2019  2019-01-22   \n",
      "\n",
      "  Day of week  Length                            Genre First time or rerun  \\\n",
      "1     Tuesday       2  Ongoing Comedy Series (Sitcoms)                  No   \n",
      "\n",
      "  # of episode in the season Movie? Game of the Canadiens during episode?  \\\n",
      "1                        Yes     No                                    No   \n",
      "\n",
      "   Temperature in Montreal during episode  \n",
      "1                                 -22.525  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(1))\n",
    "print('-------------------------------------------------')\n",
    "print(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan value with 0 in train and test data\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nominal features to numerical for train and test data\n",
    "lb_make = LabelEncoder()\n",
    "df_train[\"Episode\"] = lb_make.fit_transform(df_train[\"Episode\"])\n",
    "df_train[\"Station\"] = lb_make.fit_transform(df_train[\"Station\"])\n",
    "df_train[\"Channel Type\"] = lb_make.fit_transform(df_train[\"Channel Type\"])\n",
    "df_train[\"Season\"] = lb_make.fit_transform(df_train[\"Season\"])\n",
    "df_train[\"Year\"] = lb_make.fit_transform(df_train[\"Year\"])\n",
    "df_train[\"Date\"] = lb_make.fit_transform(df_train[\"Date\"])\n",
    "df_train[\"Day of week\"] = lb_make.fit_transform(df_train[\"Day of week\"])\n",
    "df_train[\"Genre\"] = lb_make.fit_transform(df_train[\"Genre\"])\n",
    "df_train[\"First time or rerun\"] = lb_make.fit_transform(df_train[\"First time or rerun\"])\n",
    "df_train[\"# of episode in the season\"] = lb_make.fit_transform(df_train[\"# of episode in the season\"])\n",
    "df_train[\"Movie?\"] = lb_make.fit_transform(df_train[\"Movie?\"])\n",
    "df_train[\"Game of the Canadiens during episode?\"] = lb_make.fit_transform(df_train[\"Game of the Canadiens during episode?\"])\n",
    "\n",
    "# df_train[\"Start_time\"] = lb_make.fit_transform(df_train[\"Start_time\"])\n",
    "# df_train[\"End_time\"] = lb_make.fit_transform(df_train[\"End_time\"])\n",
    "# df_train[\"Name of show\"] = lb_make.fit_transform(df_train[\"Name of show\"])\n",
    "# df_train[\"Name of episode\"] = lb_make.fit_transform(df_train[\"Name of episode\"])\n",
    "\n",
    "\n",
    "df_test[\"Episode\"] = lb_make.fit_transform(df_test[\"Episode\"])\n",
    "df_test[\"Station\"] = lb_make.fit_transform(df_test[\"Station\"])\n",
    "df_test[\"Channel Type\"] = lb_make.fit_transform(df_test[\"Channel Type\"])\n",
    "df_test[\"Season\"] = lb_make.fit_transform(df_test[\"Season\"])\n",
    "df_test[\"Year\"] = lb_make.fit_transform(df_test[\"Year\"])\n",
    "df_test[\"Date\"] = lb_make.fit_transform(df_test[\"Date\"])\n",
    "df_test[\"Day of week\"] = lb_make.fit_transform(df_test[\"Day of week\"])\n",
    "df_test[\"Genre\"] = lb_make.fit_transform(df_test[\"Genre\"])\n",
    "df_test[\"First time or rerun\"] = lb_make.fit_transform(df_test[\"First time or rerun\"])\n",
    "df_test[\"# of episode in the season\"] = lb_make.fit_transform(df_test[\"# of episode in the season\"])\n",
    "df_test[\"Movie?\"] = lb_make.fit_transform(df_test[\"Movie?\"])\n",
    "df_test[\"Game of the Canadiens during episode?\"] = lb_make.fit_transform(df_test[\"Game of the Canadiens during episode?\"])\n",
    "\n",
    "# df_test[\"Start_time\"] = lb_make.fit_transform(df_test[\"Start_time\"])\n",
    "# df_test[\"End_time\"] = lb_make.fit_transform(df_test[\"End_time\"])\n",
    "# df_test[\"Name of show\"] = lb_make.fit_transform(df_test[\"Name of show\"])\n",
    "# df_test[\"Name of episode\"] = lb_make.fit_transform(df_test[\"Name of episode\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Episode  Station  Channel Type  Season  Year  Date  Day of week  Length  \\\n",
      "1     6388       21             0       0     0     0            1       8   \n",
      "\n",
      "   Genre  First time or rerun  # of episode in the season  Movie?  \\\n",
      "1     11                    0                           1       0   \n",
      "\n",
      "   Game of the Canadiens during episode?  \\\n",
      "1                                      0   \n",
      "\n",
      "   Temperature in Montreal during episode  \n",
      "1                                    20.4  \n",
      "   Episode  Station  Channel Type  Season  Year  Date  Day of week  Length  \\\n",
      "1     1487       20             1       2     0     0            5       2   \n",
      "\n",
      "   Genre  First time or rerun  # of episode in the season  Movie?  \\\n",
      "1     15                    0                           1       0   \n",
      "\n",
      "   Game of the Canadiens during episode?  \\\n",
      "1                                      0   \n",
      "\n",
      "   Temperature in Montreal during episode  \n",
      "1                                 -22.525  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(1))\n",
    "print(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616656, 14)\n",
      "(154165, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with min_max normalizer\n",
    "min_max_normalizer = MinMaxScaler()\n",
    "min_max_normalizer.fit(df_train)\n",
    "#normalize train data\n",
    "train_data = min_max_normalizer.transform(df_train)\n",
    "\n",
    "#normalize test data\n",
    "test_data = min_max_normalizer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.037242    0.91304348  0.          0.          0.          0.\n",
      "  0.16666667  0.02173913  0.30769231  0.          1.          0.          0.\n",
      "  0.74629259]\n",
      "[ 0.00209393  0.86956522  1.          0.66666667  0.          0.\n",
      "  0.83333333  0.02173913  0.57692308  0.          1.          0.          0.\n",
      "  0.09298597]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])\n",
    "print(test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616656, 14)\n"
     ]
    }
   ],
   "source": [
    "# dadehaye test chon label nadarand ta model ra behtar arzyabi konim, 20 hezar dade az train joda karde va serfan jahate test model az anha estefade shode\n",
    "print(train_data.shape)\n",
    "x_test = train_data[:20000]\n",
    "y_test = train_label[:20000]\n",
    "new_train_data = train_data[20000:]\n",
    "new_train_label = train_label[20000:]\n",
    "x_train, x_val, y_train, y_val = train_test_split(new_train_data, new_train_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(weight_matrix):\n",
    "    return K.random_uniform(shape=weight_matrix, minval=-1.2, maxval=0.8, seed=(142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu',\n",
    "                input_shape=(train_data.shape[1],), kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.add(Dense(16, activation='relu', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.add(Dense(4, activation='relu', kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.add(Dense(1, kernel_initializer=initializer, bias_initializer='zeros'))\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_history = history.history['mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 501), mae_history, 'b', label='mean_absolute_error')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('mae_validation')\n",
    "plt.title('Mean_absolute_error validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(x_test, y_test)\n",
    "print(test_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = model.predict(x_test)\n",
    "print(prd[:40])\n",
    "print(y_test[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 3,745\n",
      "Trainable params: 3,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 477324 samples, validate on 119332 samples\n",
      "Epoch 1/50\n",
      "477324/477324 [==============================] - 4s 8us/step - loss: 2.1204 - mean_absolute_error: 2.1204 - val_loss: 1.9519 - val_mean_absolute_error: 1.9519\n",
      "Epoch 2/50\n",
      "477324/477324 [==============================] - 3s 7us/step - loss: 1.8127 - mean_absolute_error: 1.8127 - val_loss: 1.7422 - val_mean_absolute_error: 1.7422\n",
      "Epoch 3/50\n",
      "477324/477324 [==============================] - 5s 9us/step - loss: 1.6967 - mean_absolute_error: 1.6967 - val_loss: 1.6706 - val_mean_absolute_error: 1.6706\n",
      "Epoch 4/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.6501 - mean_absolute_error: 1.6501 - val_loss: 1.6384 - val_mean_absolute_error: 1.6384\n",
      "Epoch 5/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.6289 - mean_absolute_error: 1.6289 - val_loss: 1.6176 - val_mean_absolute_error: 1.6176\n",
      "Epoch 6/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.6156 - mean_absolute_error: 1.6156 - val_loss: 1.6104 - val_mean_absolute_error: 1.6104\n",
      "Epoch 7/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.6026 - mean_absolute_error: 1.6026 - val_loss: 1.5977 - val_mean_absolute_error: 1.5977\n",
      "Epoch 8/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5902 - mean_absolute_error: 1.5902 - val_loss: 1.5783 - val_mean_absolute_error: 1.5783\n",
      "Epoch 9/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5758 - mean_absolute_error: 1.5758 - val_loss: 1.5621 - val_mean_absolute_error: 1.5621\n",
      "Epoch 10/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5578 - mean_absolute_error: 1.5578 - val_loss: 1.5485 - val_mean_absolute_error: 1.5485\n",
      "Epoch 11/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5408 - mean_absolute_error: 1.5408 - val_loss: 1.5375 - val_mean_absolute_error: 1.5375\n",
      "Epoch 12/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5296 - mean_absolute_error: 1.5296 - val_loss: 1.5238 - val_mean_absolute_error: 1.5238\n",
      "Epoch 13/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5181 - mean_absolute_error: 1.5181 - val_loss: 1.5182 - val_mean_absolute_error: 1.5182\n",
      "Epoch 14/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5107 - mean_absolute_error: 1.5107 - val_loss: 1.5036 - val_mean_absolute_error: 1.5036\n",
      "Epoch 15/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.5038 - mean_absolute_error: 1.5038 - val_loss: 1.4997 - val_mean_absolute_error: 1.4997\n",
      "Epoch 16/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4987 - mean_absolute_error: 1.4987 - val_loss: 1.4952 - val_mean_absolute_error: 1.4952\n",
      "Epoch 17/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4937 - mean_absolute_error: 1.4937 - val_loss: 1.4873 - val_mean_absolute_error: 1.4873\n",
      "Epoch 18/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4890 - mean_absolute_error: 1.4890 - val_loss: 1.4800 - val_mean_absolute_error: 1.4800\n",
      "Epoch 19/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4843 - mean_absolute_error: 1.4843 - val_loss: 1.4788 - val_mean_absolute_error: 1.4788\n",
      "Epoch 20/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4801 - mean_absolute_error: 1.4801 - val_loss: 1.4833 - val_mean_absolute_error: 1.4833\n",
      "Epoch 21/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4762 - mean_absolute_error: 1.4762 - val_loss: 1.5005 - val_mean_absolute_error: 1.5005\n",
      "Epoch 22/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4731 - mean_absolute_error: 1.4731 - val_loss: 1.4800 - val_mean_absolute_error: 1.4800\n",
      "Epoch 23/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4693 - mean_absolute_error: 1.4693 - val_loss: 1.4759 - val_mean_absolute_error: 1.4759\n",
      "Epoch 24/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4653 - mean_absolute_error: 1.4653 - val_loss: 1.4755 - val_mean_absolute_error: 1.4755\n",
      "Epoch 25/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4638 - mean_absolute_error: 1.4638 - val_loss: 1.4750 - val_mean_absolute_error: 1.4750\n",
      "Epoch 26/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4604 - mean_absolute_error: 1.4604 - val_loss: 1.4836 - val_mean_absolute_error: 1.4836\n",
      "Epoch 27/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4581 - mean_absolute_error: 1.4581 - val_loss: 1.4737 - val_mean_absolute_error: 1.4737\n",
      "Epoch 28/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4560 - mean_absolute_error: 1.4560 - val_loss: 1.4654 - val_mean_absolute_error: 1.4654\n",
      "Epoch 29/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4544 - mean_absolute_error: 1.4544 - val_loss: 1.4611 - val_mean_absolute_error: 1.4611\n",
      "Epoch 30/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4521 - mean_absolute_error: 1.4521 - val_loss: 1.4630 - val_mean_absolute_error: 1.4630\n",
      "Epoch 31/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4505 - mean_absolute_error: 1.4505 - val_loss: 1.4583 - val_mean_absolute_error: 1.4583\n",
      "Epoch 32/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4475 - mean_absolute_error: 1.4475 - val_loss: 1.4583 - val_mean_absolute_error: 1.4583\n",
      "Epoch 33/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4453 - mean_absolute_error: 1.4453 - val_loss: 1.4536 - val_mean_absolute_error: 1.4536\n",
      "Epoch 34/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4430 - mean_absolute_error: 1.4430 - val_loss: 1.4519 - val_mean_absolute_error: 1.4519\n",
      "Epoch 35/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4423 - mean_absolute_error: 1.4423 - val_loss: 1.4563 - val_mean_absolute_error: 1.4563\n",
      "Epoch 36/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4407 - mean_absolute_error: 1.4407 - val_loss: 1.4514 - val_mean_absolute_error: 1.4514\n",
      "Epoch 37/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4385 - mean_absolute_error: 1.4385 - val_loss: 1.4483 - val_mean_absolute_error: 1.4483\n",
      "Epoch 38/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4368 - mean_absolute_error: 1.4368 - val_loss: 1.4529 - val_mean_absolute_error: 1.4529\n",
      "Epoch 39/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4348 - mean_absolute_error: 1.4348 - val_loss: 1.4405 - val_mean_absolute_error: 1.4405\n",
      "Epoch 40/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4342 - mean_absolute_error: 1.4342 - val_loss: 1.4475 - val_mean_absolute_error: 1.4475\n",
      "Epoch 41/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4328 - mean_absolute_error: 1.4328 - val_loss: 1.4404 - val_mean_absolute_error: 1.4404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4315 - mean_absolute_error: 1.4315 - val_loss: 1.4364 - val_mean_absolute_error: 1.4364\n",
      "Epoch 43/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4287 - mean_absolute_error: 1.4287 - val_loss: 1.4448 - val_mean_absolute_error: 1.4448\n",
      "Epoch 44/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4273 - mean_absolute_error: 1.4273 - val_loss: 1.4400 - val_mean_absolute_error: 1.4400\n",
      "Epoch 45/50\n",
      "477324/477324 [==============================] - 3s 6us/step - loss: 1.4256 - mean_absolute_error: 1.4256 - val_loss: 1.4424 - val_mean_absolute_error: 1.4424\n",
      "Epoch 46/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4244 - mean_absolute_error: 1.4244 - val_loss: 1.4322 - val_mean_absolute_error: 1.4322\n",
      "Epoch 47/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4230 - mean_absolute_error: 1.4230 - val_loss: 1.4298 - val_mean_absolute_error: 1.4298\n",
      "Epoch 48/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4216 - mean_absolute_error: 1.4216 - val_loss: 1.4297 - val_mean_absolute_error: 1.4297\n",
      "Epoch 49/50\n",
      "477324/477324 [==============================] - 5s 11us/step - loss: 1.4215 - mean_absolute_error: 1.4215 - val_loss: 1.4282 - val_mean_absolute_error: 1.4282\n",
      "Epoch 50/50\n",
      "477324/477324 [==============================] - 5s 10us/step - loss: 1.4198 - mean_absolute_error: 1.4198 - val_loss: 1.4343 - val_mean_absolute_error: 1.4343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad9703b160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=0\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(64, activation='relu',\n",
    "                input_shape=(train_data.shape[1],)))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(4, activation='relu'))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "model2.summary()\n",
    "model2.fit(x_train, y_train, epochs=50, batch_size=512, validation_data=(x_val, y_val), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 1s 37us/step\n",
      "1.51149394699\n"
     ]
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model2.evaluate(x_test, y_test)\n",
    "print(test_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.4643462 ]\n",
      " [  8.0877285 ]\n",
      " [  0.64489806]\n",
      " [  5.04695225]\n",
      " [ 12.75297356]\n",
      " [  7.40807676]\n",
      " [  4.60941219]\n",
      " [  6.62042141]\n",
      " [  7.45935726]\n",
      " [  7.48206234]\n",
      " [  9.80313492]\n",
      " [  2.91742945]\n",
      " [  2.89431429]\n",
      " [  5.22084808]\n",
      " [  7.28268099]\n",
      " [ 12.40941811]\n",
      " [  5.94057035]\n",
      " [  5.99242306]\n",
      " [  7.5569663 ]\n",
      " [  6.25339317]\n",
      " [  7.41461182]\n",
      " [  7.20410633]\n",
      " [  6.38549423]\n",
      " [  1.62750328]\n",
      " [  7.6813612 ]\n",
      " [  6.30175495]\n",
      " [  2.38631964]\n",
      " [  2.39670897]\n",
      " [  3.95491219]\n",
      " [  4.33710051]]\n",
      "1      0.9\n",
      "2      0.5\n",
      "3      0.3\n",
      "4      1.7\n",
      "5      2.2\n",
      "6      2.7\n",
      "7      2.3\n",
      "8      1.4\n",
      "9      7.5\n",
      "10    12.1\n",
      "11    10.7\n",
      "12     5.5\n",
      "13     5.8\n",
      "14    10.5\n",
      "15     9.8\n",
      "16    11.4\n",
      "17     8.0\n",
      "18     7.8\n",
      "19     7.0\n",
      "20     8.6\n",
      "21     3.0\n",
      "22     3.3\n",
      "23     3.6\n",
      "24     2.1\n",
      "25     9.9\n",
      "26     6.7\n",
      "27     0.9\n",
      "28     2.3\n",
      "29     2.9\n",
      "30     4.9\n",
      "Name: Market Share_total, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# chon test set label nadasht, 20000 record az train joda va baraye test avaliye kenar gozashte shod. in 20000 dade\n",
    "# dar faze amoozesh hich tasiri nadashte\n",
    "prd = model2.predict(x_test)\n",
    "print(prd[:30])\n",
    "print(y_test[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dade haye test, tavasote modele train shode predict shode va natije dar zir aamade\n",
    "prd_test = model2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00404403]\n",
      " [-0.00148746]\n",
      " [-0.00265792]\n",
      " [ 0.58935928]\n",
      " [ 0.00258479]\n",
      " [ 0.00326023]\n",
      " [ 0.00320402]\n",
      " [-0.00303212]\n",
      " [-0.00272837]\n",
      " [-0.00305256]\n",
      " [ 0.63427794]\n",
      " [ 0.63084519]\n",
      " [ 0.25627068]\n",
      " [ 0.63358068]\n",
      " [ 0.67063653]\n",
      " [-0.00330427]\n",
      " [-0.00330254]\n",
      " [ 0.00322559]\n",
      " [ 1.24228406]\n",
      " [ 1.40937984]]\n"
     ]
    }
   ],
   "source": [
    "print(prd_test[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
